{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from PIL import Image\n",
    "from six.moves import range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (17900, 28, 28) (17900,)\n",
      "validation set (1000, 28, 28) (1000,)\n",
      "test set (1000, 28, 28) (1000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file= '/input/banglaLekha_mini_clean.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save=pickle.load(f)\n",
    "    train_dataset=save['train_dataset']\n",
    "    train_labels=save['train_labels']\n",
    "    valid_dataset=save['valid_dataset_clean']\n",
    "    valid_labels=save['valid_labels']\n",
    "    test_dataset=save['test_dataset_clean']\n",
    "    test_labels=save['test_labels']\n",
    "    del save #hint to help gc to free up memory \n",
    "    print('training set', train_dataset.shape,train_labels.shape)\n",
    "    print('validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (17900, 28, 28, 1) (17900, 10)\n",
      "validation set (1000, 28, 28, 1) (1000, 10)\n",
      "test set (1000, 28, 28, 1) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size=28\n",
    "num_labels=10\n",
    "num_channels=1 \n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset=dataset.reshape((-1,image_size,image_size,num_channels)).astype(np.float32)\n",
    "    # Map 1 to [0.0,1.0,0.0....], 2 to [0.0,0.0,1.0.....]\n",
    "    labels=(np.arange(num_labels) ==labels[:,None]).astype(np.float32)\n",
    "    return dataset,labels\n",
    "train_dataset, train_labels= reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels=reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels =reformat(test_dataset, test_labels)\n",
    "print( 'training set', train_dataset.shape,train_labels.shape)\n",
    "print('validation set', valid_dataset.shape,valid_labels.shape)\n",
    "print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns accuracy of model\n",
    "def accuracy(target,predictions):\n",
    "    return(100.0*np.sum(np.argmax(target,1) == np.argmax(predictions,1))/target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to batch the test data because running low on memory\n",
    "class test_batchs:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.batch_index = 0\n",
    "    def nextBatch(self,batch_size):\n",
    "        if (batch_size+self.batch_index) > self.data.shape[0]:\n",
    "            print (\"batch sized is messed up\")\n",
    "        batch = self.data[self.batch_index:(self.batch_index+batch_size),:,:,:]\n",
    "        self.batch_index= self.batch_index+batch_size\n",
    "        return batch\n",
    "\n",
    "#set the test batchsize\n",
    "test_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use os to get our current working directory so we can save variable\n",
    "file_path = os.getcwd()+'/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"tf_train_dataset:0\", shape=(50, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D:0\", shape=(50, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_1:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(50, 14, 14, 16), dtype=float32) Tensor(\"Relu_3:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_4:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_5:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat:0\", shape=(50, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_6:0\", shape=(50, 14, 14, 24), dtype=float32) Tensor(\"Relu_7:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_8:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_9:0\", shape=(50, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_1:0\", shape=(50, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_4:0\", shape=(50, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(50, 3528), dtype=float32)\n",
      "Tensor(\"dropout/mul:0\", shape=(50, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_11:0\", shape=(50, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_12:0\", shape=(50, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_train_dataset:0\", shape=(50, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_10:0\", shape=(50, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_5:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_13:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_11:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_6:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_14:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_15:0\", shape=(50, 14, 14, 16), dtype=float32) Tensor(\"Relu_16:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_17:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_18:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_4:0\", shape=(50, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_19:0\", shape=(50, 14, 14, 24), dtype=float32) Tensor(\"Relu_20:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_21:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_22:0\", shape=(50, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_5:0\", shape=(50, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_9:0\", shape=(50, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_4:0\", shape=(50, 3528), dtype=float32)\n",
      "Tensor(\"Relu_23:0\", shape=(50, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_24:0\", shape=(50, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_25:0\", shape=(50, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_valid_dataset:0\", shape=(1000, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_20:0\", shape=(1000, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_10:0\", shape=(1000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_26:0\", shape=(1000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_21:0\", shape=(1000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_11:0\", shape=(1000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_27:0\", shape=(1000, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_28:0\", shape=(1000, 14, 14, 16), dtype=float32) Tensor(\"Relu_29:0\", shape=(1000, 14, 14, 8), dtype=float32) Tensor(\"Relu_30:0\", shape=(1000, 14, 14, 8), dtype=float32) Tensor(\"Relu_31:0\", shape=(1000, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_6:0\", shape=(1000, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_32:0\", shape=(1000, 14, 14, 24), dtype=float32) Tensor(\"Relu_33:0\", shape=(1000, 14, 14, 12), dtype=float32) Tensor(\"Relu_34:0\", shape=(1000, 14, 14, 12), dtype=float32) Tensor(\"Relu_35:0\", shape=(1000, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_7:0\", shape=(1000, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_14:0\", shape=(1000, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(1000, 3528), dtype=float32)\n",
      "Tensor(\"Relu_36:0\", shape=(1000, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_37:0\", shape=(1000, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_38:0\", shape=(1000, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_test_dataset:0\", shape=(1000, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_30:0\", shape=(1000, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_15:0\", shape=(1000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_39:0\", shape=(1000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_31:0\", shape=(1000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_16:0\", shape=(1000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_40:0\", shape=(1000, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_41:0\", shape=(1000, 14, 14, 16), dtype=float32) Tensor(\"Relu_42:0\", shape=(1000, 14, 14, 8), dtype=float32) Tensor(\"Relu_43:0\", shape=(1000, 14, 14, 8), dtype=float32) Tensor(\"Relu_44:0\", shape=(1000, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_8:0\", shape=(1000, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_45:0\", shape=(1000, 14, 14, 24), dtype=float32) Tensor(\"Relu_46:0\", shape=(1000, 14, 14, 12), dtype=float32) Tensor(\"Relu_47:0\", shape=(1000, 14, 14, 12), dtype=float32) Tensor(\"Relu_48:0\", shape=(1000, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_9:0\", shape=(1000, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_19:0\", shape=(1000, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_6:0\", shape=(1000, 3528), dtype=float32)\n",
      "Tensor(\"Relu_49:0\", shape=(1000, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_50:0\", shape=(1000, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_51:0\", shape=(1000, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_input:0\", shape=(1, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_40:0\", shape=(1, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_20:0\", shape=(1, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_52:0\", shape=(1, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_41:0\", shape=(1, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_21:0\", shape=(1, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_53:0\", shape=(1, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_54:0\", shape=(1, 14, 14, 16), dtype=float32) Tensor(\"Relu_55:0\", shape=(1, 14, 14, 8), dtype=float32) Tensor(\"Relu_56:0\", shape=(1, 14, 14, 8), dtype=float32) Tensor(\"Relu_57:0\", shape=(1, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_10:0\", shape=(1, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_58:0\", shape=(1, 14, 14, 24), dtype=float32) Tensor(\"Relu_59:0\", shape=(1, 14, 14, 12), dtype=float32) Tensor(\"Relu_60:0\", shape=(1, 14, 14, 12), dtype=float32) Tensor(\"Relu_61:0\", shape=(1, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_11:0\", shape=(1, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_24:0\", shape=(1, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_7:0\", shape=(1, 3528), dtype=float32)\n",
      "Tensor(\"Relu_62:0\", shape=(1, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_63:0\", shape=(1, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_64:0\", shape=(1, 512), dtype=float32)\n",
      "after fully Connected\n",
      "WARNING:tensorflow:From <ipython-input-6-51c09aea555e>:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.300516\n",
      "Minibatch accuracy: 6.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 100: 0.614341\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 71.2%\n",
      "Minibatch loss at step 200: 0.430149\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 300: 0.282045\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 400: 0.228767\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 500: 0.273397\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 600: 0.235331\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 700: 0.440256\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 800: 0.316334\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 900: 0.224575\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 1000: 0.231176\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 95.0%\n",
      "Minibatch loss at step 1100: 0.191702\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 1200: 0.166144\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 95.5%\n",
      "Minibatch loss at step 1300: 0.096440\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 95.5%\n",
      "Minibatch loss at step 1400: 0.443116\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 95.4%\n",
      "Minibatch loss at step 1500: 0.151703\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 1600: 0.053620\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 95.9%\n",
      "Minibatch loss at step 1700: 0.213658\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 95.5%\n",
      "Minibatch loss at step 1800: 0.190313\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 95.1%\n",
      "Minibatch loss at step 1900: 0.076773\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 96.0%\n",
      "Minibatch loss at step 2000: 0.053034\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 97.3%\n",
      "Minibatch loss at step 2100: 0.145508\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 96.9%\n",
      "Minibatch loss at step 2200: 0.236997\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 95.8%\n",
      "Minibatch loss at step 2300: 0.131307\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 96.7%\n",
      "Minibatch loss at step 2400: 0.146373\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 96.7%\n",
      "Minibatch loss at step 2500: 0.022266\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 95.3%\n",
      "Minibatch loss at step 2600: 0.071893\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.0%\n",
      "Minibatch loss at step 2700: 0.050464\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 96.9%\n",
      "Minibatch loss at step 2800: 0.280994\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 95.8%\n",
      "Minibatch loss at step 2900: 0.171405\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 96.5%\n",
      "Minibatch loss at step 3000: 0.047871\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 97.1%\n",
      "Minibatch loss at step 3100: 0.020324\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 97.4%\n",
      "Minibatch loss at step 3200: 0.129835\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.0%\n",
      "Minibatch loss at step 3300: 0.109945\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.9%\n",
      "Minibatch loss at step 3400: 0.102579\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 3500: 0.049899\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 3600: 0.048152\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 3700: 0.062589\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 97.7%\n",
      "Minibatch loss at step 3800: 0.085910\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 3900: 0.068437\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.2%\n",
      "Minibatch loss at step 4000: 0.003271\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.8%\n",
      "Minibatch loss at step 4100: 0.009921\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 4200: 0.006687\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 4300: 0.132324\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 97.4%\n",
      "Minibatch loss at step 4400: 0.005468\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.8%\n",
      "Minibatch loss at step 4500: 0.017521\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 4600: 0.021732\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 96.7%\n",
      "Minibatch loss at step 4700: 0.325943\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 97.6%\n",
      "Minibatch loss at step 4800: 0.052233\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.0%\n",
      "Minibatch loss at step 4900: 0.110895\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 5000: 0.003186\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 5100: 0.050332\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 5200: 0.016181\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 5300: 0.026144\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.7%\n",
      "Minibatch loss at step 5400: 0.044392\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 5500: 0.017128\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 5600: 0.079352\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 5700: 0.075085\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 5800: 0.002168\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 5900: 0.003586\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Minibatch loss at step 6000: 0.021579\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 6100: 0.020452\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 6200: 0.104704\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 6300: 0.044005\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 6400: 0.035245\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 6500: 0.004494\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 6600: 0.020404\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.9%\n",
      "Minibatch loss at step 6700: 0.004053\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 6800: 0.004577\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 6900: 0.039225\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.1%\n",
      "Minibatch loss at step 7000: 0.017718\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 7100: 0.003365\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 7200: 0.002911\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 7300: 0.005924\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 7400: 0.010661\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 7500: 0.002308\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 7600: 0.151562\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 7700: 0.004728\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 7800: 0.014430\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 7900: 0.018765\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 8000: 0.001453\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 8100: 0.125988\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 8200: 0.017698\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 8300: 0.000536\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 8400: 0.014952\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 8500: 0.008905\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 8600: 0.001653\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 8700: 0.126978\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 8800: 0.001162\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 8900: 0.009482\n",
      "Minibatch accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 9000: 0.007316\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 9100: 0.020428\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 9200: 0.048859\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 9300: 0.001913\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 9400: 0.000360\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.2%\n",
      "Minibatch loss at step 9500: 0.038925\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 9600: 0.009757\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 9700: 0.024738\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 9800: 0.056165\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 9900: 0.007517\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 10000: 0.019330\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 10100: 0.011489\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 10200: 0.048183\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 10300: 0.058220\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 10400: 0.000056\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 10500: 0.009198\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 10600: 0.005795\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 10700: 0.084555\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.0%\n",
      "Minibatch loss at step 10800: 0.002472\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 10900: 0.106266\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 11000: 0.106415\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 11100: 0.002624\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 11200: 0.041172\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 11300: 0.003215\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 11400: 0.000201\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 11500: 0.000618\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 11600: 0.005777\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 11700: 0.014049\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 11800: 0.074990\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 11900: 0.002829\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 12000: 0.011285\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 12100: 0.015516\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 12200: 0.001214\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.1%\n",
      "Minibatch loss at step 12300: 0.000357\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 12400: 0.002399\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 12500: 0.004260\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 12600: 0.006318\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 12700: 0.007883\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 12800: 0.006999\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 12900: 0.000056\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 13000: 0.130810\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 13100: 0.004576\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 13200: 0.000190\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 13300: 0.009397\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 13400: 0.004002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 13500: 0.001491\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 13600: 0.062300\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.3%\n",
      "Minibatch loss at step 13700: 0.000558\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 13800: 0.034975\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 13900: 0.000109\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.3%\n",
      "Minibatch loss at step 14000: 0.006615\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 14100: 0.000189\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 14200: 0.000036\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 14300: 0.002124\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 14400: 0.000370\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 14500: 0.003505\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 14600: 0.001345\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 14700: 0.038763\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 14800: 0.000739\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 14900: 0.054257\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 15000: 0.010369\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 15100: 0.001469\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 15200: 0.015663\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 15300: 0.005883\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 15400: 0.063105\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 15500: 0.028583\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 15600: 0.173315\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 15700: 0.000951\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 15800: 0.000344\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 15900: 0.000582\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 16000: 0.000599\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 16100: 0.000061\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 16200: 0.004391\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 16300: 0.207256\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 16400: 0.000177\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 16500: 0.006502\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 16600: 0.031348\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 16700: 0.003639\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 16800: 0.000259\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 16900: 0.000087\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.0%\n",
      "Minibatch loss at step 17000: 0.008956\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 17100: 0.003412\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 17200: 0.106890\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 17300: 0.000080\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 17400: 0.246985\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 17500: 0.046041\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 17600: 0.048676\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 17700: 0.001732\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 17800: 0.014763\n",
      "Minibatch accuracy: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 17900: 0.005714\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 18000: 0.000601\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 18100: 0.016781\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 18200: 0.066645\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 18300: 0.006886\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 18400: 0.001824\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 18500: 0.000603\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 18600: 0.010217\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 97.8%\n",
      "Minibatch loss at step 18700: 0.000094\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 18800: 0.001939\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 18900: 0.073476\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 19000: 0.006501\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 19100: 0.004544\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 19200: 0.064269\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 19300: 0.004331\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 19400: 0.000200\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 19500: 0.000132\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 19600: 0.000435\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 19700: 0.002012\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 19800: 0.001302\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 19900: 0.000565\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 20000: 0.000237\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 20100: 0.000196\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 20200: 0.021543\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 20300: 0.002644\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 20400: 0.070825\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 20500: 0.015056\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 20600: 0.000399\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 20700: 0.080129\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 20800: 0.000093\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 20900: 0.000268\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 21000: 0.019769\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 21100: 0.011432\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 21200: 0.019404\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 21300: 0.020041\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 21400: 0.000066\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 21500: 0.000034\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 21600: 0.000082\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 21700: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 21800: 0.000223\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.4%\n",
      "Minibatch loss at step 21900: 0.007637\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 22000: 0.000909\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 22100: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 22200: 0.000228\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 22300: 0.000543\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 22400: 0.025269\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 22500: 0.000150\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 22600: 0.002136\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 22700: 0.002224\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 22800: 0.000210\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 22900: 0.002100\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 23000: 0.000473\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 23100: 0.000521\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 23200: 0.000685\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 23300: 0.018125\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 23400: 0.010824\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 23500: 0.000114\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 23600: 0.005937\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 23700: 0.002160\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 23800: 0.000083\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 23900: 0.001703\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 24000: 0.000035\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 24100: 0.079201\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 24200: 0.000098\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 24300: 0.000013\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 24400: 0.074760\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 24500: 0.023313\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 24600: 0.011364\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 24700: 0.000004\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 24800: 0.026573\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 24900: 0.000563\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 25000: 0.077033\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 25100: 0.000286\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 25200: 0.000127\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 25300: 0.029288\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 25400: 0.000151\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 25500: 0.003925\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 25600: 0.000392\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 25700: 0.006042\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 25800: 0.000710\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 25900: 0.017462\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 26000: 0.005906\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 26100: 0.021760\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 26200: 0.007219\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 26300: 0.000012\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 26400: 0.001663\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 26500: 0.010031\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 26600: 0.000148\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 26700: 0.025075\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 26800: 0.016101\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 26900: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 27000: 0.206337\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.6%\n",
      "Minibatch loss at step 27100: 0.009386\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 27200: 0.110980\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 27300: 0.003350\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 27400: 0.000187\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 27500: 0.000512\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 27600: 0.000007\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 27700: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 27800: 0.000196\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 27900: 0.006602\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 28000: 0.009016\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 28100: 0.000338\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 28200: 0.000661\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.1%\n",
      "Minibatch loss at step 28300: 0.028230\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 28400: 0.000230\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.2%\n",
      "Minibatch loss at step 28500: 0.024586\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 28600: 0.000136\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 28700: 0.000005\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Minibatch loss at step 28800: 0.045707\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 28900: 0.000201\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 29000: 0.002473\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 29100: 0.028242\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 29200: 0.000057\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 29300: 0.003900\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 29400: 0.000006\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 29500: 0.000004\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 29600: 0.000118\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.7%\n",
      "Minibatch loss at step 29700: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.8%\n",
      "Minibatch loss at step 29800: 0.019403\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.5%\n",
      "Minibatch loss at step 29900: 0.000003\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 99.0%\n",
      "Minibatch loss at step 30000: 0.015371\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 98.9%\n",
      "Test accuracy: 95.4%\n",
      "Model saved in: /output/banglaInception_mini_M2.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "def deeper_inception_conv_net():\n",
    "    \n",
    "    batch_size = 50\n",
    "    patch_size1 = 3\n",
    "    patch_size2 = 5\n",
    "    depth = 16\n",
    "    depth1 = 32\n",
    "    depth2 = 16\n",
    "    depth3 = 8\n",
    "    concat_depth = 72 #concat_depth = depth2+depth3+depth3+depth2\n",
    "    num_hidden = 1024\n",
    "    num_hidden2 = 512\n",
    "    keep_prob = 0.5\n",
    "    decay_step = 2000\n",
    "    base = 0.9\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        # Input data.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels),name=\"tf_train_dataset\")\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name=\"tf_train_labels\")\n",
    "        tf_valid_dataset = tf.constant(valid_dataset,name=\"tf_valid_dataset\")\n",
    "        tf_test_dataset = tf.constant(test_dataset,name=\"tf_test_dataset\")\n",
    "        ##input for inference\n",
    "        tf_input=tf.placeholder(tf.float32, shape=(1, image_size, image_size, num_channels),name=\"tf_input\")\n",
    "        ##Output for inference\n",
    "        #output=tf.placeholder(tf.float32, shape=(1, num_labels),name=\"output\")\n",
    "        # Variables.\n",
    "        layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, num_channels, depth], stddev=0.3),name=\"layer1_weights\")\n",
    "        layer1_biases = tf.Variable(tf.zeros([depth]),name=\"layer1_biases\")\n",
    "        layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, depth, depth1], stddev=0.05),name=\"layer2_weights\")\n",
    "        layer2_biases = tf.Variable(tf.constant(0.0, shape=[depth1]),name=\"layer2_biases\")\n",
    "        layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "          [((image_size + 3) // 4) * ((image_size + 3) // 4) * concat_depth, num_hidden], stddev=0.05),name=\"layer3_weights\")\n",
    "        layer3_biases = tf.Variable(tf.constant(0.0, shape=[num_hidden]),name=\"layer3_biases\")\n",
    "        layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "          [num_hidden, num_hidden2], stddev=0.01),name=\"layer4_weights\")\n",
    "        layer4_biases = tf.Variable(tf.constant(0.0, shape=[num_hidden2]),name=\"layer4_biases\")\n",
    "        layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "          [num_hidden2, num_labels], stddev=0.01),name=\"layer5_weights\")\n",
    "        layer5_biases = tf.Variable(tf.constant(0.0, shape=[num_labels]),name=\"layer5_biases\")\n",
    "\n",
    "        inception1x1_weights = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, depth1, depth2], stddev=0.25),name=\"inception1x1_weights\")\n",
    "        inception1x1_biases = tf.Variable(tf.constant(0.0, shape=[depth2]),name=\"inception1x1_biases\")\n",
    "        inception3x3_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, depth2, depth3], stddev=0.05),name=\"inception3x3_weights\")\n",
    "        inception3x3_biases = tf.Variable(tf.constant(0.0, shape=[depth3]),name=\"inception3x3_biases\")\n",
    "        inception5x5_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, depth2, depth3], stddev=0.08),name=\"inception5x5_weights\")\n",
    "        inception5x5_biases = tf.Variable(tf.constant(0.0, shape=[depth3]),name=\"inception5x5_biases\")\n",
    "\n",
    "        inception1x1_post_mxpool_wts = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, depth1, depth2], stddev=0.04),name=\"inception1x1_post_mxpool_wts\")\n",
    "        post_maxpool_biases = tf.Variable(tf.constant(0.0, shape=[depth2]),name=\"post_maxpool_biases\")\n",
    "\n",
    "\n",
    "        ##For inception module2\n",
    "        inception1x1_weights_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, 48, 24], stddev=0.25),name=\"inception1x1_weights_mod2\")\n",
    "        inception1x1_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[24]),name=\"inception1x1_biases_mod2\")\n",
    "        inception3x3_weights_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, 24, 12], stddev=0.05),name=\"inception3x3_weights_mod2\")\n",
    "        inception3x3_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[12]),name=\"inception3x3_biases_mod2\")\n",
    "        inception5x5_weights_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, 24, 12], stddev=0.08),name=\"inception5x5_weights_mod2\")\n",
    "        inception5x5_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[12]),name=\"inception5x5_biases_mod2\")\n",
    "\n",
    "        inception1x1_post_mxpool_wts_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, 48, 24], stddev=0.04),name=\"inception1x1_post_mxpool_wts_mod2\")\n",
    "        post_maxpool_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[24]),name=\"post_maxpool_biases_mod2\")\n",
    "        #End of inception module2\n",
    "\n",
    "        global_step = tf.Variable(0, trainable = False)  # count the number of steps taken.\n",
    "        learning_rate = tf.train.exponential_decay(0.005, global_step, decay_step, base)\n",
    "        \n",
    "        \n",
    "        # Model.\n",
    "        def model(data, useDropout):\n",
    "            print(data)\n",
    "            conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            print(conv)\n",
    "            max_pooled = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "            print(max_pooled)\n",
    "            hidden = tf.nn.relu(max_pooled + layer1_biases)\n",
    "            print(hidden)\n",
    "            conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            print(conv)\n",
    "            max_pooled = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')\n",
    "            print(max_pooled)\n",
    "            hidden = tf.nn.relu(max_pooled + layer2_biases)\n",
    "            print(hidden)\n",
    "            print(\"b4 inception\")\n",
    "            print(inception1x1_weights)\n",
    "            print(inception3x3_weights)\n",
    "            print(inception5x5_weights)\n",
    "            inception1x1_conv = tf.nn.conv2d(hidden, inception1x1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_relu = tf.nn.relu(inception1x1_conv + inception1x1_biases)\n",
    "\n",
    "            inception3x3_conv = tf.nn.conv2d(inception1x1_relu, inception3x3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            inception3x3_relu = tf.nn.relu(inception3x3_conv + inception3x3_biases)\n",
    "\n",
    "            inception5x5_conv = tf.nn.conv2d(inception1x1_relu, inception5x5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            inception5x5_relu = tf.nn.relu(inception5x5_conv + inception5x5_biases)\n",
    "\n",
    "            inception3x3_maxpool = tf.nn.max_pool(hidden, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.conv2d(inception3x3_maxpool, inception1x1_post_mxpool_wts, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.relu(inception1x1_post_maxpool + post_maxpool_biases)\n",
    "            print(inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool)\n",
    "            concat_filter = tf.concat([inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool],3)\n",
    "            print(\"after inception\")\n",
    "            print(concat_filter)\n",
    "\n",
    "            print(\"b4 inception 2\")\n",
    "\n",
    "            inception1x1_conv = tf.nn.conv2d(concat_filter, inception1x1_weights_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_relu = tf.nn.relu(inception1x1_conv + inception1x1_biases_mod2)\n",
    "\n",
    "            inception3x3_conv = tf.nn.conv2d(inception1x1_relu, inception3x3_weights_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception3x3_relu = tf.nn.relu(inception3x3_conv + inception3x3_biases_mod2)\n",
    "\n",
    "            inception5x5_conv = tf.nn.conv2d(inception1x1_relu, inception5x5_weights_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception5x5_relu = tf.nn.relu(inception5x5_conv + inception5x5_biases_mod2)\n",
    "\n",
    "            inception3x3_maxpool = tf.nn.max_pool(concat_filter, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.conv2d(inception3x3_maxpool, inception1x1_post_mxpool_wts_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.relu(inception1x1_post_maxpool + post_maxpool_biases_mod2)\n",
    "            print(inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool)\n",
    "            concat_filter = tf.concat([inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool],3)\n",
    "            print(\"after inception 2\")\n",
    "            print(concat_filter)\n",
    "\n",
    "            concat_maxpooled = tf.nn.max_pool(concat_filter, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "            print(concat_maxpooled)\n",
    "            shape = concat_maxpooled.get_shape().as_list()\n",
    "\n",
    "            reshape = tf.reshape(concat_maxpooled, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "            print(reshape)\n",
    "            if useDropout == 1:\n",
    "                dropout_layer2 = tf.nn.dropout(tf.nn.relu(reshape), keep_prob)\n",
    "            else:\n",
    "                dropout_layer2 = tf.nn.relu(reshape)\n",
    "            print(dropout_layer2)\n",
    "            print(\"1st fc\")\n",
    "            hidden = tf.nn.relu(tf.matmul(dropout_layer2, layer3_weights) + layer3_biases)\n",
    "            print(hidden)\n",
    "            print(\"2nd fc\")\n",
    "            hidden = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "            print(hidden)\n",
    "            print(\"after fully Connected\")\n",
    "            return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "\n",
    "        # Training computation.\n",
    "        logits = model(tf_train_dataset, 1)\n",
    "        loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels),name=\"loss\")\n",
    "\n",
    "        # Optimizer.\n",
    "        optimizer = tf.train.AdamOptimizer(0.001).minimize(loss, global_step=global_step)\n",
    "\n",
    "        # Predictions for the training, validation, and test data.\n",
    "        train_prediction = tf.nn.softmax(model(tf_train_dataset, 0),name=\"train_prediction\")\n",
    "        valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 0),name=\"valid_prediction\")\n",
    "        test_prediction = tf.nn.softmax(model(tf_test_dataset, 0),name=\"test_prediction\")\n",
    "        output=tf.nn.softmax(model(tf_input,0),name=\"output\")\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    num_steps = 30001\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print('Initialized')\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 100 == 0):\n",
    "                print('Minibatch loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "                #print(tf.Print(layer1_weights, [layer1_weights]).eval())\n",
    "                model_path=saver.save(session,'/output/banglaInception_mini_M2.ckpt', global_step=step)\n",
    "                print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "        print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels)) \n",
    "        print('Model saved in: %s' % model_path)\n",
    "deeper_inception_conv_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
