{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from PIL import Image\n",
    "from six.moves import range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (139000, 28, 28) (139000,)\n",
      "validation set (10000, 28, 28) (10000,)\n",
      "test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file= '/input/banglaIsolated_clean.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save=pickle.load(f)\n",
    "    train_dataset=save['train_dataset']\n",
    "    train_labels=save['train_labels']\n",
    "    valid_dataset=save['valid_dataset_clean']\n",
    "    valid_labels=save['valid_labels']\n",
    "    test_dataset=save['test_dataset_clean']\n",
    "    test_labels=save['test_labels']\n",
    "    del save #hint to help gc to free up memory \n",
    "    print('training set', train_dataset.shape,train_labels.shape)\n",
    "    print('validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (139000, 28, 28, 1) (139000, 84)\n",
      "validation set (10000, 28, 28, 1) (10000, 84)\n",
      "test set (10000, 28, 28, 1) (10000, 84)\n"
     ]
    }
   ],
   "source": [
    "image_size=28\n",
    "num_labels=84\n",
    "num_channels=1 \n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset=dataset.reshape((-1,image_size,image_size,num_channels)).astype(np.float32)\n",
    "    # Map 1 to [0.0,1.0,0.0....], 2 to [0.0,0.0,1.0.....]\n",
    "    labels=(np.arange(num_labels) ==labels[:,None]).astype(np.float32)\n",
    "    return dataset,labels\n",
    "train_dataset, train_labels= reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels=reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels =reformat(test_dataset, test_labels)\n",
    "print( 'training set', train_dataset.shape,train_labels.shape)\n",
    "print('validation set', valid_dataset.shape,valid_labels.shape)\n",
    "print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns accuracy of model\n",
    "def accuracy(target,predictions):\n",
    "    return(100.0*np.sum(np.argmax(target,1) == np.argmax(predictions,1))/target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to batch the test data because running low on memory\n",
    "class test_batchs:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.batch_index = 0\n",
    "    def nextBatch(self,batch_size):\n",
    "        if (batch_size+self.batch_index) > self.data.shape[0]:\n",
    "            print (\"batch sized is messed up\")\n",
    "        batch = self.data[self.batch_index:(self.batch_index+batch_size),:,:,:]\n",
    "        self.batch_index= self.batch_index+batch_size\n",
    "        return batch\n",
    "\n",
    "#set the test batchsize\n",
    "test_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use os to get our current working directory so we can save variable\n",
    "file_path = os.getcwd()+'/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"tf_train_dataset:0\", shape=(50, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D:0\", shape=(50, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_1:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(50, 14, 14, 16), dtype=float32) Tensor(\"Relu_3:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_4:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_5:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat:0\", shape=(50, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_6:0\", shape=(50, 14, 14, 24), dtype=float32) Tensor(\"Relu_7:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_8:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_9:0\", shape=(50, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_1:0\", shape=(50, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_4:0\", shape=(50, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(50, 3528), dtype=float32)\n",
      "Tensor(\"dropout/mul:0\", shape=(50, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_11:0\", shape=(50, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_12:0\", shape=(50, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_train_dataset:0\", shape=(50, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_10:0\", shape=(50, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_5:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_13:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_11:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_6:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_14:0\", shape=(50, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_15:0\", shape=(50, 14, 14, 16), dtype=float32) Tensor(\"Relu_16:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_17:0\", shape=(50, 14, 14, 8), dtype=float32) Tensor(\"Relu_18:0\", shape=(50, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_4:0\", shape=(50, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_19:0\", shape=(50, 14, 14, 24), dtype=float32) Tensor(\"Relu_20:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_21:0\", shape=(50, 14, 14, 12), dtype=float32) Tensor(\"Relu_22:0\", shape=(50, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_5:0\", shape=(50, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_9:0\", shape=(50, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_4:0\", shape=(50, 3528), dtype=float32)\n",
      "Tensor(\"Relu_23:0\", shape=(50, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_24:0\", shape=(50, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_25:0\", shape=(50, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_valid_dataset:0\", shape=(10000, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_20:0\", shape=(10000, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_10:0\", shape=(10000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_26:0\", shape=(10000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_21:0\", shape=(10000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_11:0\", shape=(10000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_27:0\", shape=(10000, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_28:0\", shape=(10000, 14, 14, 16), dtype=float32) Tensor(\"Relu_29:0\", shape=(10000, 14, 14, 8), dtype=float32) Tensor(\"Relu_30:0\", shape=(10000, 14, 14, 8), dtype=float32) Tensor(\"Relu_31:0\", shape=(10000, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_6:0\", shape=(10000, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_32:0\", shape=(10000, 14, 14, 24), dtype=float32) Tensor(\"Relu_33:0\", shape=(10000, 14, 14, 12), dtype=float32) Tensor(\"Relu_34:0\", shape=(10000, 14, 14, 12), dtype=float32) Tensor(\"Relu_35:0\", shape=(10000, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_7:0\", shape=(10000, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_14:0\", shape=(10000, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_5:0\", shape=(10000, 3528), dtype=float32)\n",
      "Tensor(\"Relu_36:0\", shape=(10000, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_37:0\", shape=(10000, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_38:0\", shape=(10000, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_test_dataset:0\", shape=(10000, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_30:0\", shape=(10000, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_15:0\", shape=(10000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_39:0\", shape=(10000, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_31:0\", shape=(10000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_16:0\", shape=(10000, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_40:0\", shape=(10000, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_41:0\", shape=(10000, 14, 14, 16), dtype=float32) Tensor(\"Relu_42:0\", shape=(10000, 14, 14, 8), dtype=float32) Tensor(\"Relu_43:0\", shape=(10000, 14, 14, 8), dtype=float32) Tensor(\"Relu_44:0\", shape=(10000, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_8:0\", shape=(10000, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_45:0\", shape=(10000, 14, 14, 24), dtype=float32) Tensor(\"Relu_46:0\", shape=(10000, 14, 14, 12), dtype=float32) Tensor(\"Relu_47:0\", shape=(10000, 14, 14, 12), dtype=float32) Tensor(\"Relu_48:0\", shape=(10000, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_9:0\", shape=(10000, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_19:0\", shape=(10000, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_6:0\", shape=(10000, 3528), dtype=float32)\n",
      "Tensor(\"Relu_49:0\", shape=(10000, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_50:0\", shape=(10000, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_51:0\", shape=(10000, 512), dtype=float32)\n",
      "after fully Connected\n",
      "Tensor(\"tf_input:0\", shape=(1, 28, 28, 1), dtype=float32)\n",
      "Tensor(\"Conv2D_40:0\", shape=(1, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"MaxPool_20:0\", shape=(1, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Relu_52:0\", shape=(1, 14, 14, 16), dtype=float32)\n",
      "Tensor(\"Conv2D_41:0\", shape=(1, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"MaxPool_21:0\", shape=(1, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"Relu_53:0\", shape=(1, 14, 14, 32), dtype=float32)\n",
      "b4 inception\n",
      "Tensor(\"inception1x1_weights/read:0\", shape=(1, 1, 32, 16), dtype=float32)\n",
      "Tensor(\"inception3x3_weights/read:0\", shape=(3, 3, 16, 8), dtype=float32)\n",
      "Tensor(\"inception5x5_weights/read:0\", shape=(5, 5, 16, 8), dtype=float32)\n",
      "Tensor(\"Relu_54:0\", shape=(1, 14, 14, 16), dtype=float32) Tensor(\"Relu_55:0\", shape=(1, 14, 14, 8), dtype=float32) Tensor(\"Relu_56:0\", shape=(1, 14, 14, 8), dtype=float32) Tensor(\"Relu_57:0\", shape=(1, 14, 14, 16), dtype=float32)\n",
      "after inception\n",
      "Tensor(\"concat_10:0\", shape=(1, 14, 14, 48), dtype=float32)\n",
      "b4 inception 2\n",
      "Tensor(\"Relu_58:0\", shape=(1, 14, 14, 24), dtype=float32) Tensor(\"Relu_59:0\", shape=(1, 14, 14, 12), dtype=float32) Tensor(\"Relu_60:0\", shape=(1, 14, 14, 12), dtype=float32) Tensor(\"Relu_61:0\", shape=(1, 14, 14, 24), dtype=float32)\n",
      "after inception 2\n",
      "Tensor(\"concat_11:0\", shape=(1, 14, 14, 72), dtype=float32)\n",
      "Tensor(\"MaxPool_24:0\", shape=(1, 7, 7, 72), dtype=float32)\n",
      "Tensor(\"Reshape_7:0\", shape=(1, 3528), dtype=float32)\n",
      "Tensor(\"Relu_62:0\", shape=(1, 3528), dtype=float32)\n",
      "1st fc\n",
      "Tensor(\"Relu_63:0\", shape=(1, 1024), dtype=float32)\n",
      "2nd fc\n",
      "Tensor(\"Relu_64:0\", shape=(1, 512), dtype=float32)\n",
      "after fully Connected\n",
      "WARNING:tensorflow:From <ipython-input-9-da780c7f4832>:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 4.431573\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 100: 3.659979\n",
      "Minibatch accuracy: 6.0%\n",
      "Validation accuracy: 12.0%\n",
      "Minibatch loss at step 200: 2.981443\n",
      "Minibatch accuracy: 24.0%\n",
      "Validation accuracy: 27.7%\n",
      "Minibatch loss at step 300: 2.462240\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 38.1%\n",
      "Minibatch loss at step 400: 1.905987\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 50.1%\n",
      "Minibatch loss at step 500: 1.525109\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 57.2%\n",
      "Minibatch loss at step 600: 1.519067\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 60.9%\n",
      "Minibatch loss at step 700: 1.212067\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 63.8%\n",
      "Minibatch loss at step 800: 1.222964\n",
      "Minibatch accuracy: 70.0%\n",
      "Validation accuracy: 68.1%\n",
      "Minibatch loss at step 900: 0.924427\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 70.2%\n",
      "Minibatch loss at step 1000: 0.894234\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 72.3%\n",
      "Minibatch loss at step 1100: 0.899923\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 72.3%\n",
      "Minibatch loss at step 1200: 1.266053\n",
      "Minibatch accuracy: 62.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 1300: 0.580403\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 1400: 1.053206\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1500: 0.711071\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 1600: 1.053118\n",
      "Minibatch accuracy: 74.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1700: 1.040025\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1800: 0.724832\n",
      "Minibatch accuracy: 76.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1900: 0.695361\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2000: 0.728477\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 2100: 0.860479\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2200: 0.758942\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 2300: 0.900076\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2400: 0.974959\n",
      "Minibatch accuracy: 76.0%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 2500: 0.729459\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 2600: 1.147167\n",
      "Minibatch accuracy: 72.0%\n",
      "Validation accuracy: 83.4%\n",
      "Minibatch loss at step 2700: 0.430655\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 83.4%\n",
      "Minibatch loss at step 2800: 0.696221\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 2900: 0.688677\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 3000: 0.803433\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 3100: 0.986654\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 3200: 0.803129\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 3300: 0.724063\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 3400: 0.762329\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 3500: 0.724410\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 3600: 0.555467\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 3700: 0.531113\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 3800: 0.556148\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 3900: 0.838381\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 4000: 0.788089\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 4100: 0.651815\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 4200: 0.586785\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 4300: 1.271449\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 4400: 0.573283\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 4500: 0.644211\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 4600: 0.707448\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 4700: 0.423468\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 4800: 0.720392\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4900: 0.495062\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5000: 0.542570\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5100: 0.462020\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5200: 0.268553\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5300: 0.647202\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 5400: 0.465678\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 5500: 0.368448\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5600: 0.420994\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5700: 0.372412\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5800: 0.569826\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5900: 0.600065\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 6000: 0.424898\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 6100: 0.691636\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 6200: 0.191945\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 6300: 0.844053\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 6400: 0.387223\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 6500: 0.434062\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 6600: 0.449437\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 6700: 0.513954\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 6800: 0.930282\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 6900: 0.393058\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 7000: 0.474555\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 7100: 0.215899\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 7200: 0.400014\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7300: 0.579175\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 7400: 0.942195\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 7500: 0.485749\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 7600: 0.376144\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 7700: 0.301264\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 7800: 0.528942\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 7900: 0.474850\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 8000: 0.428152\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 8100: 0.605179\n",
      "Minibatch accuracy: 78.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 8200: 0.675010\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 8300: 0.595028\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 8400: 0.451937\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 8500: 0.564872\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 8600: 0.266133\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 8700: 0.833636\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 8800: 0.351692\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 8900: 0.416348\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 9000: 0.475919\n",
      "Minibatch accuracy: 86.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 9100: 0.424912\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 9200: 0.481834\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 9300: 0.452290\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 9400: 0.484656\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 9500: 0.208677\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 9600: 0.274161\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 9700: 0.777506\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 9800: 0.700114\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 9900: 0.306652\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 10000: 0.300734\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 10100: 0.385585\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 10200: 0.191753\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 10300: 0.513798\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 10400: 0.433754\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 10500: 0.466353\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 10600: 0.672716\n",
      "Minibatch accuracy: 84.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 10700: 0.276567\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 10800: 0.084001\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 10900: 0.267049\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 11000: 0.591632\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 11100: 0.211373\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 11200: 0.161287\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 11300: 0.388250\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 11400: 0.343943\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 11500: 0.347893\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 11600: 0.384924\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 11700: 0.544178\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 11800: 0.308880\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 11900: 0.288814\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 12000: 0.355351\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 12100: 0.510147\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 12200: 0.548693\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 12300: 0.104978\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 12400: 0.315917\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 12500: 0.295261\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 12600: 0.118374\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 12700: 0.431162\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 12800: 0.386287\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 12900: 0.178819\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 13000: 0.534538\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 13100: 0.497414\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 13200: 0.372080\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 13300: 0.678892\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 13400: 0.391694\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 13500: 0.483479\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 13600: 0.454379\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 13700: 0.351407\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 13800: 0.485667\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 13900: 0.451103\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 14000: 1.106004\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 14100: 0.329420\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 14200: 0.530244\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 14300: 0.274083\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 14400: 0.602866\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 14500: 0.157316\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 14600: 0.244858\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 14700: 0.202841\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 14800: 0.358877\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 14900: 0.045984\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 15000: 0.417462\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 15100: 0.511485\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 15200: 0.240501\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 15300: 0.041582\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 15400: 0.460790\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 15500: 0.213095\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 15600: 0.143433\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 15700: 0.429986\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 15800: 0.457537\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 15900: 0.119664\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 16000: 0.380572\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 16100: 0.306285\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 16200: 0.098688\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 16300: 0.263005\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 16400: 0.400563\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 16500: 0.290736\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 16600: 0.433423\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 16700: 0.216689\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 16800: 0.152762\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 16900: 0.367786\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 17000: 0.380458\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 17100: 0.373926\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 17200: 0.535649\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 17300: 0.709576\n",
      "Minibatch accuracy: 80.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 17400: 0.415677\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 17500: 0.202565\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 17600: 0.463216\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 17700: 0.263949\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 17800: 0.163101\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 17900: 0.292076\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 18000: 0.393656\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 18100: 0.095050\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 18200: 0.449810\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 18300: 0.283647\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 18400: 0.215227\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 18500: 0.294160\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 18600: 0.394300\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 18700: 0.260480\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 18800: 0.479051\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 18900: 0.383618\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 19000: 0.441242\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 19100: 0.375448\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 19200: 0.153587\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 19300: 0.362200\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 19400: 0.075978\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 19500: 0.144866\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 19600: 0.368918\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 19700: 0.237887\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 19800: 0.261037\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 19900: 0.358850\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 20000: 0.136040\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 20100: 0.158907\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 20200: 0.324537\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 20300: 0.230592\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 20400: 0.251747\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 20500: 0.191623\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 20600: 0.161161\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 20700: 0.240064\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 20800: 0.191300\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 20900: 0.349571\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 21000: 0.371764\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 21100: 0.184029\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 21200: 0.315210\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 21300: 0.112611\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 21400: 0.226711\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 21500: 0.304814\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 21600: 0.288936\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 21700: 0.450319\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 21800: 0.319507\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 21900: 0.176209\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 22000: 0.134281\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 22100: 0.261300\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 22200: 0.183889\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 22300: 0.259661\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 22400: 0.250968\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 22500: 0.140303\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 22600: 0.428803\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 22700: 0.223928\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 22800: 0.143354\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 22900: 0.260128\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 23000: 0.203508\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.4%\n",
      "Minibatch loss at step 23100: 0.193261\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 23200: 0.361551\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 23300: 0.343254\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 23400: 0.188040\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 23500: 0.282640\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 23600: 0.121550\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 23700: 0.538605\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 23800: 0.252936\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 23900: 0.156480\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 24000: 0.155109\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 24100: 0.261291\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 24200: 0.166714\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 24300: 0.535082\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 24400: 0.120245\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 24500: 0.273439\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 24600: 0.348513\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.6%\n",
      "Minibatch loss at step 24700: 0.218216\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 24800: 0.550054\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 24900: 0.145885\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 25000: 0.236854\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 25100: 0.472771\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 25200: 0.260584\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 25300: 0.276569\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 25400: 0.196565\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.6%\n",
      "Minibatch loss at step 25500: 0.271813\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 25600: 0.091523\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.4%\n",
      "Minibatch loss at step 25700: 0.181711\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 25800: 0.143204\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 25900: 0.230609\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 26000: 0.395951\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 26100: 0.112953\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 26200: 0.351312\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.6%\n",
      "Minibatch loss at step 26300: 0.080089\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 26400: 0.275120\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 26500: 0.114941\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 26600: 0.152558\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 26700: 0.277464\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 26800: 0.174369\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 26900: 0.693166\n",
      "Minibatch accuracy: 86.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 27000: 0.499260\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 27100: 0.390144\n",
      "Minibatch accuracy: 88.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 27200: 0.303716\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 27300: 0.265748\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 27400: 0.344153\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 27500: 0.161504\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 27600: 0.160210\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 27700: 0.158438\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 27800: 0.345999\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 27900: 0.254815\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 28000: 0.058875\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 28100: 0.214844\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 28200: 0.278099\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 28300: 0.234589\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 28400: 0.286246\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 95.1%\n",
      "Minibatch loss at step 28500: 0.139179\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 95.1%\n",
      "Minibatch loss at step 28600: 0.226561\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 95.0%\n",
      "Minibatch loss at step 28700: 0.115843\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 28800: 0.418213\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 95.3%\n",
      "Minibatch loss at step 28900: 0.519719\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 95.1%\n",
      "Minibatch loss at step 29000: 0.132743\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 29100: 0.149866\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 95.0%\n",
      "Minibatch loss at step 29200: 0.261924\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 29300: 0.188500\n",
      "Minibatch accuracy: 96.0%\n",
      "Validation accuracy: 94.9%\n",
      "Minibatch loss at step 29400: 0.298443\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 95.2%\n",
      "Minibatch loss at step 29500: 0.179090\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.8%\n",
      "Minibatch loss at step 29600: 0.410832\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 29700: 0.327751\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 95.3%\n",
      "Minibatch loss at step 29800: 0.157989\n",
      "Minibatch accuracy: 94.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 29900: 0.354019\n",
      "Minibatch accuracy: 90.0%\n",
      "Validation accuracy: 95.0%\n",
      "Minibatch loss at step 30000: 0.345926\n",
      "Minibatch accuracy: 92.0%\n",
      "Validation accuracy: 94.8%\n",
      "Test accuracy: 88.9%\n",
      "Model saved in: /output/banglaInceptionM2.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "def deeper_inception_conv_net():\n",
    "    \n",
    "    batch_size = 50\n",
    "    patch_size1 = 3\n",
    "    patch_size2 = 5\n",
    "    depth = 16\n",
    "    depth1 = 32\n",
    "    depth2 = 16\n",
    "    depth3 = 8\n",
    "    concat_depth = 72 #concat_depth = depth2+depth3+depth3+depth2\n",
    "    num_hidden = 1024\n",
    "    num_hidden2 = 512\n",
    "    keep_prob = 0.5\n",
    "    decay_step = 2000\n",
    "    base = 0.9\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        # Input data.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels),name=\"tf_train_dataset\")\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels),name=\"tf_train_labels\")\n",
    "        tf_valid_dataset = tf.constant(valid_dataset,name=\"tf_valid_dataset\")\n",
    "        tf_test_dataset = tf.constant(test_dataset,name=\"tf_test_dataset\")\n",
    "        ##input for inference\n",
    "        tf_input=tf.placeholder(tf.float32, shape=(1, image_size, image_size, num_channels),name=\"tf_input\")\n",
    "        ##Output for inference\n",
    "        #output=tf.placeholder(tf.float32, shape=(1, num_labels),name=\"output\")\n",
    "        # Variables.\n",
    "        layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, num_channels, depth], stddev=0.3),name=\"layer1_weights\")\n",
    "        layer1_biases = tf.Variable(tf.zeros([depth]),name=\"layer1_biases\")\n",
    "        layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, depth, depth1], stddev=0.05),name=\"layer2_weights\")\n",
    "        layer2_biases = tf.Variable(tf.constant(0.0, shape=[depth1]),name=\"layer2_biases\")\n",
    "        layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "          [((image_size + 3) // 4) * ((image_size + 3) // 4) * concat_depth, num_hidden], stddev=0.05),name=\"layer3_weights\")\n",
    "        layer3_biases = tf.Variable(tf.constant(0.0, shape=[num_hidden]),name=\"layer3_biases\")\n",
    "        layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "          [num_hidden, num_hidden2], stddev=0.01),name=\"layer4_weights\")\n",
    "        layer4_biases = tf.Variable(tf.constant(0.0, shape=[num_hidden2]),name=\"layer4_biases\")\n",
    "        layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "          [num_hidden2, num_labels], stddev=0.01),name=\"layer5_weights\")\n",
    "        layer5_biases = tf.Variable(tf.constant(0.0, shape=[num_labels]),name=\"layer5_biases\")\n",
    "\n",
    "        inception1x1_weights = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, depth1, depth2], stddev=0.25),name=\"inception1x1_weights\")\n",
    "        inception1x1_biases = tf.Variable(tf.constant(0.0, shape=[depth2]),name=\"inception1x1_biases\")\n",
    "        inception3x3_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, depth2, depth3], stddev=0.05),name=\"inception3x3_weights\")\n",
    "        inception3x3_biases = tf.Variable(tf.constant(0.0, shape=[depth3]),name=\"inception3x3_biases\")\n",
    "        inception5x5_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, depth2, depth3], stddev=0.08),name=\"inception5x5_weights\")\n",
    "        inception5x5_biases = tf.Variable(tf.constant(0.0, shape=[depth3]),name=\"inception5x5_biases\")\n",
    "\n",
    "        inception1x1_post_mxpool_wts = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, depth1, depth2], stddev=0.04),name=\"inception1x1_post_mxpool_wts\")\n",
    "        post_maxpool_biases = tf.Variable(tf.constant(0.0, shape=[depth2]),name=\"post_maxpool_biases\")\n",
    "\n",
    "\n",
    "        ##For inception module2\n",
    "        inception1x1_weights_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, 48, 24], stddev=0.25),name=\"inception1x1_weights_mod2\")\n",
    "        inception1x1_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[24]),name=\"inception1x1_biases_mod2\")\n",
    "        inception3x3_weights_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, 24, 12], stddev=0.05),name=\"inception3x3_weights_mod2\")\n",
    "        inception3x3_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[12]),name=\"inception3x3_biases_mod2\")\n",
    "        inception5x5_weights_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, 24, 12], stddev=0.08),name=\"inception5x5_weights_mod2\")\n",
    "        inception5x5_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[12]),name=\"inception5x5_biases_mod2\")\n",
    "\n",
    "        inception1x1_post_mxpool_wts_mod2 = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, 48, 24], stddev=0.04),name=\"inception1x1_post_mxpool_wts_mod2\")\n",
    "        post_maxpool_biases_mod2 = tf.Variable(tf.constant(0.0, shape=[24]),name=\"post_maxpool_biases_mod2\")\n",
    "        #End of inception module2\n",
    "\n",
    "        global_step = tf.Variable(0, trainable = False)  # count the number of steps taken.\n",
    "        learning_rate = tf.train.exponential_decay(0.005, global_step, decay_step, base)\n",
    "        \n",
    "        \n",
    "        # Model.\n",
    "        def model(data, useDropout):\n",
    "            print(data)\n",
    "            conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            print(conv)\n",
    "            max_pooled = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "            print(max_pooled)\n",
    "            hidden = tf.nn.relu(max_pooled + layer1_biases)\n",
    "            print(hidden)\n",
    "            conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            print(conv)\n",
    "            max_pooled = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')\n",
    "            print(max_pooled)\n",
    "            hidden = tf.nn.relu(max_pooled + layer2_biases)\n",
    "            print(hidden)\n",
    "            print(\"b4 inception\")\n",
    "            print(inception1x1_weights)\n",
    "            print(inception3x3_weights)\n",
    "            print(inception5x5_weights)\n",
    "            inception1x1_conv = tf.nn.conv2d(hidden, inception1x1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_relu = tf.nn.relu(inception1x1_conv + inception1x1_biases)\n",
    "\n",
    "            inception3x3_conv = tf.nn.conv2d(inception1x1_relu, inception3x3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            inception3x3_relu = tf.nn.relu(inception3x3_conv + inception3x3_biases)\n",
    "\n",
    "            inception5x5_conv = tf.nn.conv2d(inception1x1_relu, inception5x5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "            inception5x5_relu = tf.nn.relu(inception5x5_conv + inception5x5_biases)\n",
    "\n",
    "            inception3x3_maxpool = tf.nn.max_pool(hidden, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.conv2d(inception3x3_maxpool, inception1x1_post_mxpool_wts, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.relu(inception1x1_post_maxpool + post_maxpool_biases)\n",
    "            print(inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool)\n",
    "            concat_filter = tf.concat([inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool],3)\n",
    "            print(\"after inception\")\n",
    "            print(concat_filter)\n",
    "\n",
    "            print(\"b4 inception 2\")\n",
    "\n",
    "            inception1x1_conv = tf.nn.conv2d(concat_filter, inception1x1_weights_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_relu = tf.nn.relu(inception1x1_conv + inception1x1_biases_mod2)\n",
    "\n",
    "            inception3x3_conv = tf.nn.conv2d(inception1x1_relu, inception3x3_weights_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception3x3_relu = tf.nn.relu(inception3x3_conv + inception3x3_biases_mod2)\n",
    "\n",
    "            inception5x5_conv = tf.nn.conv2d(inception1x1_relu, inception5x5_weights_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception5x5_relu = tf.nn.relu(inception5x5_conv + inception5x5_biases_mod2)\n",
    "\n",
    "            inception3x3_maxpool = tf.nn.max_pool(concat_filter, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.conv2d(inception3x3_maxpool, inception1x1_post_mxpool_wts_mod2, [1, 1, 1, 1], padding='SAME')\n",
    "            inception1x1_post_maxpool = tf.nn.relu(inception1x1_post_maxpool + post_maxpool_biases_mod2)\n",
    "            print(inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool)\n",
    "            concat_filter = tf.concat([inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool],3)\n",
    "            print(\"after inception 2\")\n",
    "            print(concat_filter)\n",
    "\n",
    "            concat_maxpooled = tf.nn.max_pool(concat_filter, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "            print(concat_maxpooled)\n",
    "            shape = concat_maxpooled.get_shape().as_list()\n",
    "\n",
    "            reshape = tf.reshape(concat_maxpooled, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "            print(reshape)\n",
    "            if useDropout == 1:\n",
    "                dropout_layer2 = tf.nn.dropout(tf.nn.relu(reshape), keep_prob)\n",
    "            else:\n",
    "                dropout_layer2 = tf.nn.relu(reshape)\n",
    "            print(dropout_layer2)\n",
    "            print(\"1st fc\")\n",
    "            hidden = tf.nn.relu(tf.matmul(dropout_layer2, layer3_weights) + layer3_biases)\n",
    "            print(hidden)\n",
    "            print(\"2nd fc\")\n",
    "            hidden = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "            print(hidden)\n",
    "            print(\"after fully Connected\")\n",
    "            return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "\n",
    "        # Training computation.\n",
    "        logits = model(tf_train_dataset, 1)\n",
    "        loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels),name=\"loss\")\n",
    "\n",
    "        # Optimizer.\n",
    "        optimizer = tf.train.AdamOptimizer(0.001).minimize(loss, global_step=global_step)\n",
    "\n",
    "        # Predictions for the training, validation, and test data.\n",
    "        train_prediction = tf.nn.softmax(model(tf_train_dataset, 0),name=\"train_prediction\")\n",
    "        valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 0),name=\"valid_prediction\")\n",
    "        test_prediction = tf.nn.softmax(model(tf_test_dataset, 0),name=\"test_prediction\")\n",
    "        output=tf.nn.softmax(model(tf_input,0),name=\"output\")\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "    num_steps = 30001\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print('Initialized')\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 100 == 0):\n",
    "                print('Minibatch loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "                #print(tf.Print(layer1_weights, [layer1_weights]).eval())\n",
    "                model_path=saver.save(session,'/output/banglaInceptionM2.ckpt', global_step=step)\n",
    "                print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "        print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels)) \n",
    "        print('Model saved in: %s' % model_path)\n",
    "deeper_inception_conv_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
